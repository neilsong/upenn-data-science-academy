---
title: "A COVID Global Economy: Policy Responses, Inflationary Concerns and Consumer Confidence"
author: "By Aaron Tom, Neil Song, Ben Zhao, Luke Melcher, and Tanvi Kigga"
date: ''
output:
  html_document:
    code_folding: show
    highlight: haddock
    number_sections: yes
    theme: lumen
    toc: yes
    toc_depth: 4
    toc_float: yes
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: '4'
urlcolor: blue
editor_options: 
  chunk_output_type: inline
---
````{r setup, include=FALSE, echo = FALSE}
knitr::opts_chunk$set(echo = FALSE, results="show", fig.width=9, fig.height=6, warning=FALSE)
options(scipen = 0, digits = 3)  # controls base R output
# check if you have ISLR package, if not, install it
if(!require('pacman')) {install.packages('pacman')}
pacman::p_load(tidyverse, dplyr, ggplot2, data.table, lubridate,
               plotROC, usmap, glmnet, car, rworldmap, countrycode, bit64, devtools, lme4, randomForest, xgboost, caret, dummies, DiagrammeR, e1071, rsvg, DiagrammeRsvg, remotes)
install_github("drsimonj/pipelearner")
install_github("mtennekes/tabplot")
install_github("erblast/oetteR")
```


Abstract

COVID-19 has drastically changed our lives, and there is no doubt that it has affected the economy as well on a global scale. The global economy in 2020 was characterized by severe decline in early stages of the pandemic and a trend of recovery in later and current stages. The goal of our study is to examine the effect that COVID-19 has had on the global economy, and to to predict trends in economic indicators for each of the countries in our data set through COVID policy. The three economic variables we chose to examine the economy from were consumer confidence index, inflation rate index (CPI), and unemployment rate. We used our data to create a double prediction layer model. We then used 4 different types of models to determine the best model for our data, we also separated data into training and testing data for the model. We then used the model to predict future economic data. Overall there is a positive correlation for consumer confidence, negative correlation for unemployment, and mostly positive correlation for inflation, over the period of July 2021-December 2021.
Methods Used
We first coded a heatmap based off of the World Bank GDP data for January 2019 of the GDP of most of the countries in the world, in order to gain perspective on the global economy and what countries we could use in our analysis. But to analyze trends in the economy, yearly data wouldnâ€™t work in the timeframe of 2-3 years, so we choose to use the OECD (Organisation for Economic Co-operation and Development) database, which is limited to about 50 countries compared to the 200+ countries in the world.
It took quite a while to find the OECD database which contained many economic indicators but also had monthly data. We realized that most main economic indicators like GDP and trade data were done either quarterly or annually.
In the end, we found several monthly economic indicators from roughly the past 30 months: unemployment rate, consumer confidence index, and inflation rate. The problem with analyzing all countries through the world bank is that some countries don't have monthly data, other countries have no data at all, so instead we have normal distribution from 28 countries of the top 100 GDP countries in the world from the OECD. When looking closer at the data, it is actually fairly normally distributed. Our OECD dataset includes countries like US #1, Finland #42 , Latvia #95 (GDP) so we have around a normal distribution of the top 100 GDP countries in the world 
Our model involves 3 layers: a base predictor layer, a 1st layer, and a 2nd layer which is the prediction layer. The base layer contains: Month, Year, Country, Covid Rate. The 1st layer contains Covid policy data: Public Campaigns, Vaccination Policies, School Closures, Stay at Home Orders. The prediction layer contains economic data: Unemployment Rates, Consumer Confidence, and Inflation Rates 

Graphical EDA from Slides

In our EDA (exploratory data analysis), there was a surge in unemployment rates in the beginning of the pandemic over March 2020 to April 2020. Countries that experienced the largest unemployment rates spikes were Costa Rica, Columbia, Greece, Spain, Chile, and the United States.
We saw a dip in confidence in the beginning of the pandemic, but rising confidence in recovery months in late 2020 and 2021.
Consumer confidence index is a survey that measures how optimistic or pessimistic someone is regarding their financial situation. A high confidence index indicates optimism about the market which means people will spend more money. A low confidence index indicates pessimism about the market which means that  people will spend less money, to be conservative, or save money.
Inflation grew regardless of the pandemic. We may speculate it is due to the Fed's role with low interest rates and government stimulus throughout the pandemic. Low interest rates may affect inflation as a larger availability of credit and loans leads to more money in circulation, which leads to rising inflation.
To determine the best model for our data we used: naive multiple linear regression, naive random forest, naive XGBoost Random Forest, and naive support vector machine models. After an analysis of the Least Squares Mean Error for each of these methods, we determined that SVM (Support Vector Machine) and XGBoost Random Forest were the best models for our variables.
XGBoost is a machine learning algorithm that contains packages which our team used for statistical and prediction analysis. This package is based on boosting, which compiles multiple weak models together to form a stronger comprehensive model. Support vector machine is a machine learning algorithm regression which uses the help of many vectors to improve regression classification results.
In the Residual VS fitted graph, we can say that this model is homoscedastic and linear as there are equal amounts of points above and below the line. In the second normal Q-Q plot as most of the points fall on the curve. Therefore, our plot is normal and we can conclude that all assumptions of the linear model are met. 

# Findings 
Analyzing each of the 28 countries would be too much- we will examine one country from 3 different tiers (high GDP, middle GDP, and low GDP) from our specified countries to define and analyze a trend through multiple perspectives. Findings for all 28 countries can be explored through the Rmd file. For high tier- US, middle tier- Finland , low tier- Slovenia. The predictions will be for over the time period July 2021 to December 2021. The projected increase/decrease for unemployment for the US is -11.65% , for Finland -15.5% , and for Slovenia -11.93%. The projected increase/decrease for consumer confidence for the US is 1.42%, for Finland 2.31%, and for Slovenia 0.71%. The projected increase/decrease for inflation rate for the US is 0.22%, for Finland -0.22%, and for Slovenia 0.93%. Overall there is a positive correlation for consumer confidence, negative correlation for unemployment, and mostly positive correlation for inflation. Overall there is a positive correlation for consumer confidence, negative correlation for unemployment, and mostly positive correlation for inflation, over the period of July 2021 - December 2021. Our predictions mostly match expectations of recovery for the global economy in 2021.



Bibliography

"A Gentle Introduction to XGBoost for Applied Machine Learning." Machine Learning Mastery. Last modified February 17, 2021. Accessed August 4, 2021. https://machinelearningmastery.com/gentle-introduction-xgboost-applied-machine-learning/.
"Global Economic Effects of COVID-19." Congressional Research Service. Last modified July 9, 2021. Accessed July 25, 2021. https://fas.org/sgp/crs/row/R46270.pdf.
Organisation for Economic Co-operation and Development. Accessed August 2, 2021. https://stats.oecd.org/.
"Policy Responses to the Coronavirus Pandemic." Our World in Data. Accessed August 2, 2021. https://ourworldindata.org/policy-responses-covid.
Song, Neil, Aaron Tom, Benjamin Zhao, Tanvi Kigga, and Luke Melcher. "Final Project." GitHub. Accessed August 4, 2021. https://github.com/neilsong/upenn-data-science-academy/tree/master/Final%20Project.



```{r}
gdp <- fread('GDP_per_capita_cleaned.csv')
cc <- fread('../oecd-new/monthly-consumer-confidence.csv')
infl <- fread('../oecd-new/monthly-inflation.csv')
# imex <- fread('../oecd-new/monthly-imports-exports.csv')
unem <- fread('../oecd-new/monthly-unemployment.csv')


public_campaigns <- readRDS(file = "public_campaigns.rds")
sah <- readRDS(file = "sah.rds")
school_closures <- readRDS(file = "school_closures.rds")
vaccination_policy <- readRDS(file = "vaccination_policy.rds")


cc <- cc[Country %in% unique(gdp$Country)]
infl <- infl[Country %in% unique(gdp$Country)]
# imex <- imex[Country %in% unique(gdp$Country)]
unem <- unem[Country %in% unique(gdp$Country)]
netcont <- Reduce(intersect, list(unique(cc$Country), unique(infl$Country), unique(unem$Country)))

cc <- cc %>% dplyr::select(LOCATION, Country, TIME, Value) %>%
    rename(code = LOCATION, month = TIME, value = Value, country =Country) %>%
    filter(country %in% netcont)
infl <- infl %>% dplyr::select(LOCATION, Country, TIME, Value) %>%
    rename(code = LOCATION, month = TIME, value = Value, country =Country) %>%
    filter(country %in% netcont)
unem <- unem %>% dplyr::select(LOCATION, Country, TIME, Value) %>%
    rename(code = LOCATION, month = TIME, value = Value, country =Country) %>%
    filter(country %in% netcont)

netcode <- Reduce(intersect, list(unique(cc$code), unique(infl$code), unique(unem$code)))

public_campaigns <- public_campaigns %>%
    rename(code = Code, pubcam = month_avg) %>%
    filter(code %in% netcode) %>%
    mutate(month = (substr(Month, 1,7))) %>%
    group_by(code) %>%
    dplyr::select(code, month, pubcam)

sah <- sah %>%
    rename(code = Code, sah = month_avg) %>%
    filter(code %in% netcode) %>%
    mutate(month = (substr(Month, 1,7))) %>%
    group_by(code) %>%
    dplyr::select(code, month, sah)

school_closures <- school_closures %>%
    rename(code = Code, closure = month_avg) %>%
    filter(code %in% netcode) %>%
    mutate(month = (substr(Month, 1,7))) %>%
    group_by(code) %>%
    dplyr::select(code, month, closure)

vaccination_policy <- vaccination_policy %>%
    rename(code = Code, policy = month_avg) %>%
    filter(code %in% netcode) %>%
    mutate(month = (substr(Month, 1,7))) %>%
    group_by(code) %>%
    dplyr::select(code, month, policy)

# imex <- imex %>% dplyr::select(LOCATION, Country, Variable, TIME, Value) %>%
#     rename(code = LOCATION, month = TIME, value = Value, country =Country, var = Variable) %>%
#     filter(country %in% netcont))

# imex <- imex %>% 
#     mutate(var = ifelse(var=='International trade in goods - exports', 1, 0)) %>%
#     mutate(value = as.numeric(value))

# im <- imex %>%
#     filter(var==0) %>%
#     rename(imval = value)

# ex <- imex %>%
#     filter(var==1) %>%
#     rename(exval = value)
# imex <- im %>%
#     left_join(ex, by = c('code', 'month', 'country')) %>%
#     mutate(value = exval - imval) %>%
#     dplyr::select(code, month, country, value)
# join_imex <- imex %>%
#     rename(imexval = value)
join_cc <- cc %>%
    rename(ccval = value)
join_infl <- infl %>%
    rename(inflval = value)
join_unem <- unem %>%
    rename(unemval = value)
df <- join_cc %>%
    left_join(join_infl, by = c('code', 'country', 'month')) %>%
    left_join(join_unem, by = c('code', 'country', 'month')) %>%
    left_join(public_campaigns, by = c('code', 'month')) %>%
    left_join(sah, by = c('code', 'month')) %>%
    left_join(school_closures, by = c('code', 'month')) %>%
    left_join(vaccination_policy, by = c('code', 'month'))

df[is.na(df)] <- 0
df %>%
    group_by(country) %>%
    summarize(min = range(month)[1], max=range(month)[2]) %>%
    arrange(max)
```
```{r}
#totval <- imex %>%
    #group_by(country) %>%
    #summarize(totval = sum(value)) %>%
    #arrange(desc(totval))
ggplot(cc, aes(x=month, y=value, group=country, color=country)) +
    geom_point() +
    geom_line() +
    theme_bw() +
    #theme(legend.position = "none") + 
    labs(x = "Month", y = "Consumer Confidence Index")
    theme(text = element_text(size=20),
        axis.text.x = element_text(angle=90, hjust=1)) 
ggplot(infl, aes(x=month, y=value, group=country, color=country)) +
    geom_point() +
    geom_line() +
    theme_bw() +
    #theme(legend.position = "none") +
    labs(x = "Month", y = "CPI Inflation Index")
    theme(text = element_text(size=20),
        axis.text.x = element_text(angle=90, hjust=1)) 
#ggplot(imex, aes(x=month, y=value, group=country, color=country)) +
   # geom_point() +
   # geom_line() +
   # theme_bw() +
    #theme(legend.position = "none") +
    #labs(x = "Net Exports", y = "Month")
ggplot(unem, aes(x=month, y=value, group=country, color=country)) + 
    geom_point() +
    geom_line() +
    theme_bw() +
    #theme(legend.position = "none") +
    labs(x = "Month", y = "Unemployment Rate (%)") +
    theme(text = element_text(size=20),
        axis.text.x = element_text(angle=90, hjust=1)) 
```

```{r}
# import covid data
covid <- fread('covid-new-cases.csv')
covid <- covid %>%
    rename(covid=newcase) %>%
    mutate(covid = log(covid + 71))
df <- df %>%
    left_join(covid, by = c('country', 'month'))
# drop na
df <- df %>%
    filter(!is.na(ccval)) %>%
    filter(!is.na(inflval)) %>%
    filter(!is.na(unemval)) %>%
    filter(!is.na(covid))
```

```{r Plot Data}
# ggplot(df, aes(x=log(covid+70), y=ccval, group=country, color=country)) +
#     geom_point() +
#     theme_bw()
# ggplot(df, aes(x=log(covid+70), y=ccval, group=country, color=country)) +
#     geom_point() +
#     theme_bw() + 
#     facet_wrap(~country) +
#     theme(legend.position = "none")
    
ggplot(df, aes(x=covid, y=ccval, group=country, color=country)) +
    geom_point() +
    theme_bw()
ggplot(df, aes(x=covid, y=ccval, group=country, color=country)) +
    geom_point() +
    theme_bw() + 
    geom_smooth(method = "lm", se=FALSE, color="black", formula = cov_y ~ x) +
    facet_wrap(~country) + 
    theme(legend.position = "none")
ggplot(df, aes(x=covid, y=inflval, group=country, color=country)) +
    geom_point() +
    theme_bw()
ggplot(df, aes(x=covid, y=inflval, group=country, color=country)) +
    geom_point() +
    theme_bw() + 
    geom_smooth(method = "lm", se=FALSE, color="black", formula = cov_y ~ x) +
    facet_wrap(~country) + 
    theme(legend.position = "none")
ggplot(df, aes(x=covid, y=unemval, group=country, color=country)) +
    geom_point() +
    theme_bw()
ggplot(df, aes(x=covid, y=unemval, group=country, color=country)) +
    geom_point() +
    theme_bw() +
    geom_smooth(method = "lm", se=FALSE, color="black", formula = cov_y ~ x) +
    facet_wrap(~country) +
    theme(legend.position = "none")
ggplot(covid, aes(x=month, y=covid, group=country, color=country)) +
    geom_point() +
    geom_line() +
    theme_bw()
    # theme(legend.position = "bottom")
ggplot(covid, aes(x=month, y=covid, group=country, color=country)) +
    geom_point() +
    theme_bw() +
    geom_smooth(method = "lm", se=FALSE, color="black", formula = cov_y ~ x) +
    facet_wrap(~country) +
    theme(legend.position = "none")
```

```{r Create COVID Models}
## nlin - naive multiple linear regression
## mixed - country:random mixed linear regression
## nrf - naive random forest
## xg - grid searched, naive xgboost random forest
## svm - naive svm

cov_traindf <- df %>% 
    dplyr::select(country, month, covid) %>%
    mutate(month_num = as.factor(as.numeric(substr(month, 6, 7)))) %>%
    mutate(year = as.numeric(substr(month, 1, 4))) %>%
    dplyr::select(country, month_num, year, covid) %>%
    rename(month = month_num)

set.seed(123)

cov_indices <- sample(1:nrow(cov_traindf), size = 0.75 * nrow(cov_traindf))
cov_train <- cov_traindf[cov_indices,]
cov_test <- cov_traindf[-cov_indices,]

nlin <- lm(covid ~ country + month + year, data=cov_train)
pred_nlin <- predict(nlin, cov_test)
yhat<-pred_nlin
y<-cov_test$covid

nlin_stats <- postResample(yhat,y)

mixed <- lmer(covid ~ month + year + (1|country), data=cov_train)
pred_mixed <- predict(mixed, cov_test)
yhat_mixed <- pred_mixed
y_mixed <- cov_test$covid
mixed_stats <- postResample(yhat_mixed,y_mixed)

nrf <- randomForest(covid ~ month + country + year, data=cov_train, ntree=100)
pred_nrf <- predict(nrf, cov_test)
yhat<-pred_nrf
y<-cov_test$covid

nrf_stats <- postResample(yhat,y)
```


```{r COVID SVM Model}
r <- function(data) {round(data, 1)}

title <- "COVID New Cases Support Vector Machine Regression"

cov_svm_tuned <- svm(
  formula = covid ~ month+year+country,
  data    = cov_train,
  gamma = .125,
  cost = 32,
  scale=TRUE
  )

pred_svm_tuned <- predict(cov_svm_tuned,cov_test)

yhat<-pred_svm_tuned 
y<-cov_test$covid
cov_svm_stats<-postResample(yhat,y)

# summary(cov_svm_tuned)

res <- r(cov_test$covid - pred_svm_tuned)

# plot(res, ylab = "residuals", main = title)
plot(
  cov_test$covid,
  pred_svm_tuned,
  main = title,
  ylab = "predicted",
  xlab = "actual"
)
abline(lm(pred_svm_tuned ~ cov_test$covid))
```

```{r Fit XGBoost Model COVID}
cov_title <- "Naive COVID XGBoost"

cov_tmp <- cov_traindf %>% dplyr::select(country, month)
cov_tmp1 <- dummy.data.frame(cov_tmp)
cov_d <- data.frame(cov_tmp1, cov_traindf %>% dplyr::select(year, covid))
cov_m <- as.matrix(cov_d)
cov_indices <- sample(1:nrow(cov_traindf), size = 0.75 * nrow(cov_traindf))
cov_xg_train <- cov_m[cov_indices,]
cov_xg_test <- cov_m[-cov_indices,]

cov_xg <-
  xgboost(
    data = cov_xg_train[, 1:41],
    label = cov_xg_train[, 42],
    nrounds = 1000,
    objective = "reg:squarederror",
    early_stopping_rounds = 6,
    max_depth = 3,
    eta = .36,
    nthreads = 4,
  )

cov_pred_xgb <- predict(cov_xg, cov_xg_test[, 1:41])

cov_yhat <- cov_pred_xgb
cov_y <- cov_xg_test[, 42]
cov_xg_stats <- postResample(cov_yhat, cov_y)
cov_xg_rmse <- cov_xg_stats[[1]]

cov_r <- cov_y - cov_yhat
plot(cov_r, ylab = "residuals", main = title)

plot(cov_y,
     cov_yhat,
     xlab = "actual",
     ylab = "predicted",
     main = cov_title)
abline(lm(cov_yhat ~ cov_y))

#plot first 3 trees of model
cov_trees <- xgb.plot.tree(model = cov_xg, trees = 0:2, render=F)
export_graph(cov_trees, 'tree.png', width=3000, height=4000)

cov_importance_matrix <- xgb.importance(model = cov_xg)
xgb.plot.importance(cov_importance_matrix, xlab = "COVID Feature Importance")
```

```{r Fit Econ Models}

## nlin - naive multiple linear regression
## nrf - naive random forest
## xg - naive xgboost random forest
## svm - naive svm
econ_traindf <- df %>% 
    dplyr::select(-code) %>%
    mutate(month_num = as.factor(as.numeric(substr(month, 6, 7)))) %>%
    mutate(year = as.numeric(substr(month, 1, 4))) %>%
    dplyr::select(-month) %>%
    rename(month = month_num)

set.seed(124)

econ_indices <- sample(1:nrow(econ_traindf), size = 0.75 * nrow(econ_traindf))
econ_train <- econ_traindf[cov_indices,]
econ_test <- econ_traindf[-cov_indices,]

nlincc <- lm(ccval ~. -inflval -unemval, data=econ_train)
nlincc_pred <- predict(nlincc, econ_test)
nlincc_stats <- postResample(nlincc_pred, econ_test$ccval)

nlininfl <- lm(inflval ~. -ccval -unemval, data=econ_train)
nlininfl_pred <- predict(nlininfl, econ_test)
nlininfl_stats <- postResample(nlininfl_pred, econ_test$inflval)

nlinunem <- lm(unemval ~. -ccval -inflval, data=econ_train)
nlinunem_pred <- predict(nlinunem, econ_test)
nlinunem_stats <- postResample(nlinunem_pred, econ_test$unemval)

nlinpubcam <- lm(pubcam ~covid + month + year + country, data=econ_train)
nlinpubcam_pred <- predict(nlinpubcam, econ_test)
nlinpubcam_stats <- postResample(nlinpubcam_pred, econ_test$pubcam)

nlinsah <- lm(sah ~covid + month + year + country, data=econ_train)
nlinsah_pred <- predict(nlinsah, econ_test)
nlinsah_stats <- postResample(nlinsah_pred, econ_test$sah)

nlinclosure <- lm(closure ~covid + month + year + country, data=econ_train)
nlinclosure_pred <- predict(nlinclosure, econ_test)
nlinclosure_stats <- postResample(nlinclosure_pred, econ_test$closure)

nlinpolicy <- lm(policy ~covid + month + year + country, data=econ_train)
nlinpolicy_pred <- predict(nlinpolicy, econ_test)
nlinpolicy_stats <- postResample(nlinpolicy_pred, econ_test$policy)


nrfcc <- randomForest(ccval ~. -inflval -unemval, data=econ_train, ntree=1000)
nrfcc_pred <- predict(nrfcc, econ_test)
nrfcc_stats <- postResample(nrfcc_pred, econ_test$ccval)

nrfinfl <- randomForest(inflval ~. -ccval -unemval, data=econ_train, ntree=1000)
nrfinfl_pred <- predict(nrfinfl, econ_test)
nrfinfl_stats <- postResample(nrfinfl_pred, econ_test$inflval)

nrfunem <- randomForest(unemval ~. -ccval -inflval, data=econ_train, ntree=1000)
nrfunem_pred <- predict(nrfunem, econ_test)
nrfunem_stats <- postResample(nrfunem_pred, econ_test$unemval)

nrfpubcam <- randomForest(pubcam ~covid + month + year + country, data=econ_train, ntree=1000)
nrfpubcam_pred <- predict(nrfpubcam, econ_test)
nrfpubcam_stats <- postResample(nrfpubcam_pred, econ_test$pubcam)

nrfsah <- randomForest(sah ~covid + month + year + country, data=econ_train, ntree=1000)
nrfsah_pred <- predict(nrfsah, econ_test)
nrfsah_stats <- postResample(nrfsah_pred, econ_test$sah)

nrfclosure <- randomForest(closure ~covid + month + year + country , data=econ_train, ntree=1000)
nrfclosure_pred <- predict(nrfclosure, econ_test)
nrfclosure_stats <- postResample(nrfclosure_pred, econ_test$closure)

nrfpolicy <- randomForest(policy ~ covid + month + year + country, data=econ_train, ntree=1000)
nrfpolicy_pred <- predict(nrfpolicy, econ_test)
nrfpolicy_stats <- postResample(nrfpolicy_pred, econ_test$policy)

plot(
  econ_test$ccval,
  nrfcc_pred,
  main = "Consumer Confidence Index Random Forest Regression",
  ylab = "predicted",
  xlab = "actual"
)
abline(lm(nrfcc_pred ~ econ_test$ccval))
plot(nrfcc, 
  main = "Consumer Confidence Index Random Forest Regression",)

#plot(cc_svm_tuned)

# mixedcc <- lmer(ccval ~ covid + month + year + pubcam + sah + closure + policy + (1|country), data=econ_train)
# mixedcc_pred <- predict(mixedcc, newdata = econ_test)
# mixedcc_stats <- postResample(mixedcc_pred, econ_test$ccval)

# mixedinfl <- lmer(inflval ~ covid +month + year + pubcam + sah + closure + policy + (1|country), data=econ_train)
# mixedinfl_pred <- predict(mixedinfl, data=econ_test)
# mixedinfl_stats <- postResample(mixedinfl_pred, econ_test$inflval)

# mixedunem <- lmer(unemval ~ covid +month + year + pubcam + sah + closure + policy + (1|country), data=econ_train)
# mixedunem_pred <- predict(mixedunem, econ_test)
# mixedunem_stats <- postResample(mixedunem_pred, econ_test$unemval)

# mixedpubcam <- lmer(pubcam ~ covid + month + year + (1|country), data=econ_train)
# mixedpubcam_pred <- predict(mixedpubcam, econ_test)
# mixedpubcam_stats <- postResample(mixedpubcam_pred, econ_test$pubcam)

# mixedsah <- lmer(sah ~ covid + month + year + (1|country), data=econ_train)
# mixedsah_pred <- predict(mixedsah, econ_test)
# mixedsah_stats <- postResample(mixedsah_pred, econ_test$sah)

# mixedclosure <- lmer(closure ~ covid + month + year + (1|country), data=econ_train)
# mixedclosure_pred <- predict(mixedclosure, econ_test)
# mixedclosure_stats <- postResample(mixedclosure_pred, econ_test$closure)

# mixedpolicy <- lmer(policy ~ covid + month + year + (1|country), data=econ_train)
# mixedpolicy_pred <- predict(mixedpolicy, econ_test)
# mixedpolicy_stats <- postResample(mixedpolicy_pred, econ_test$policy)

```

```{r CC Econ SVM Model}
r <- function(data) {round(data, 1)}

title <- "Consumer Confidence Index Support Vector Machine Regression"

cc_svm_tuned <- svm(
  formula = ccval ~ . - inflval - unemval,
  data    = econ_train,
  gamma = 0.03125,
  cost = 32,
  scale=TRUE
  )

pred_svm_tuned <- predict(cc_svm_tuned,econ_test)

yhat<-pred_svm_tuned 
y<-econ_test$ccval
cc_svm_stats<-postResample(yhat,y)

# summary(cc_svm_tuned)

res <- r(econ_test$ccval - pred_svm_tuned)

# plot(res, ylab = "residuals", main = title)
plot(
  econ_test$ccval,
  pred_svm_tuned,
  main = title,
  ylab = "predicted",
  xlab = "actual"
)
abline(lm(pred_svm_tuned ~ econ_test$ccval))
```

```{r Infl Econ SVM Model}
r <- function(data) {round(data, 1)}

title <- "Inflation Index Support Vector Machine Regression"

infl_svm_tuned <- svm(
  formula = inflval ~ . - ccval - unemval,
  data    = econ_train,
  gamma = 0.03125,
  cost = 32,
  scale=TRUE
  )

pred_svm_tuned <- predict(infl_svm_tuned,econ_test)

yhat<-pred_svm_tuned 
y<-econ_test$inflval
infl_svm_stats<-postResample(yhat,y)

# summary(infl_svm_tuned)

res <- r(econ_test$inflval - pred_svm_tuned)

# plot(res, ylab = "residuals", main = title)
# plot(
#   cov_test$inflval,
#   pred_svm_tuned,
#   main = title,
#   ylab = "predicted",
#   xlab = "actual"
# )
# abline(lm(pred_svm_tuned ~ cov_test$inflval))
```
```{r Unemval Econ SVM Model}
r <- function(data) {round(data, 1)}

title <- "Unemployment Index Support Vector Machine Regression"

unem_svm_tuned <- svm(
  formula = unemval ~ . - ccval - inflval,
  data    = econ_train,
  gamma = 0.125,
  cost = 2,
  scale=TRUE
  )

pred_svm_tuned <- predict(unem_svm_tuned,econ_test)

yhat<-pred_svm_tuned 
y<-econ_test$unemval
unemval_svm_stats<-postResample(yhat,y)

# summary(unem_svm_tuned)

res <- r(econ_test$unemval - pred_svm_tuned)

# plot(res, ylab = "residuals", main = title)
# plot(
#   cov_test$unemval,
#   pred_svm_tuned,
#   main = title,
#   ylab = "predicted",
#   xlab = "actual"
# )
# abline(lm(pred_svm_tuned ~ cov_test$unemval))
```

```{r Pubcam Econ SVM Model}
r <- function(data) {round(data, 1)}

title <- "Public Campaign Support Vector Machine Regression"

pubcam_svm_tuned <- svm(
  formula = pubcam ~ covid + month + year + country,
  data    = econ_train,
  gamma = 0.0625,
  cost = 32,
  scale=TRUE
  )

pred_svm_tuned <- predict(pubcam_svm_tuned,econ_test)

yhat<-pred_svm_tuned 
y<-econ_test$pubcam
pubcamval_svm_stats<-postResample(yhat,y)

# summary(pubcam_svm_tuned)

res <- r(econ_test$pubcam - pred_svm_tuned)

# plot(res, ylab = "residuals", main = title)
# plot(
#   cov_test$pubcam,
#   pred_svm_tuned,
#   main = title,
#   ylab = "predicted",
#   xlab = "actual"
# )
# abline(lm(pred_svm_tuned ~ cov_test$pubcam))
```

```{r Sah Econ SVM Model}
r <- function(data) {round(data, 1)}

title <- "Stay at Home Support Vector Machine Regression"

sah_svm_tuned <- svm(
  formula = sah ~ covid + month + year + country,
  data    = econ_train,
  gamma = 0.25,
  cost = 8,
  scale=TRUE
  )

pred_svm_tuned <- predict(sah_svm_tuned,econ_test)

yhat<-pred_svm_tuned 
y<-econ_test$sah
sahval_svm_stats<-postResample(yhat,y)

# summary(sah_svm_tuned)

res <- r(econ_test$sah - pred_svm_tuned)

# plot(res, ylab = "residuals", main = title)
# plot(
#   cov_test$sah,
#   pred_svm_tuned,
#   main = title,
#   ylab = "predicted",
#   xlab = "actual"
# )
# abline(lm(pred_svm_tuned ~ cov_test$sah))
```

```{r Closure Econ SVM Model}
r <- function(data) {round(data, 1)}

title <- "School Closure Support Vector Machine Regression"

closure_svm_tuned <- svm(
  formula = closure ~ covid + month + year + country,
  data    = econ_train,
  gamma = 0.25,
  cost = 4,
  scale=TRUE
  )

pred_svm_tuned <- predict(closure_svm_tuned,econ_test)

yhat<-pred_svm_tuned 
y<-econ_test$closure
closureval_svm_stats<-postResample(yhat,y)

# summary(closure_svm_tuned)

res <- r(econ_test$closure - pred_svm_tuned)

# plot(res, ylab = "residuals", main = title)
# plot(
#   cov_test$closure,
#   pred_svm_tuned,
#   main = title,
#   ylab = "predicted",
#   xlab = "actual"
# )
# abline(lm(pred_svm_tuned ~ cov_test$closure))
```

```{r Policy Econ SVM Model}
r <- function(data) {round(data, 1)}

title <- "Support Vector Machine Regression"

policy_svm_tuned <- svm(
  formula = policy ~ covid + month + year + country,
  data    = econ_train,
  gamma = 0.03125,
  cost = 32,
  scale=TRUE
  )

pred_svm_tuned <- predict(policy_svm_tuned,econ_test)

yhat<-pred_svm_tuned 
y<-econ_test$policy
policyval_svm_stats<-postResample(yhat,y)

# summary(policy_svm_tuned)

res <- r(econ_test$policy - pred_svm_tuned)

# plot(res, ylab = "residuals", main = title)
# plot(
#   cov_test$policy,
#   pred_svm_tuned,
#   main = title,
#   ylab = "predicted",
#   xlab = "actual"
# )
# abline(lm(pred_svm_tuned ~ cov_test$policy))
```


```{r Prep XGBoost Model Econ}

econ_tmp <- econ_traindf %>% dplyr::select(country, month)
econ_tmp1 <- dummy.data.frame(econ_tmp)
econ_d <- data.frame(econ_tmp1, econ_traindf %>% dplyr::select(-c(country, month)))
econ_m <- as.matrix(econ_d)
econ_indices <- sample(1:nrow(econ_traindf), size = 0.75 * nrow(econ_traindf))
econ_xg_train <- econ_m[econ_indices,]
econ_xg_test <- econ_m[-econ_indices,]
```

```{r Fit XGBoost Model CC}
cc_title <- "Naive CC XGBoost"

cc_xg <-
  xgboost(
    data = econ_xg_train[, c(1:40, 44:49)],
    label = econ_xg_train[, 41],
    nrounds = 1000,
    objective = "reg:squarederror",
    early_stopping_rounds = 6,
    max_depth = 5,
    eta = 0.16,
    nthreads = 4,
  )

cc_pred_xgb <- predict(cc_xg, econ_xg_test[, c(1:40, 44:49)])

cc_yhat <- cc_pred_xgb
cc_y <- econ_xg_test[, 41]
cc_xg_stats <- postResample(cc_yhat, cc_y)
cc_xg_rmse <- cc_xg_stats[[1]]

cc_r <- cc_y - cc_yhat
# plot(cc_r, ylab = "residuals", main = title)

# plot(cc_y,
#      cc_yhat,
#      xlab = "actual",
#      ylab = "predicted",
#      main = title)
# abline(lm(cc_yhat ~ cc_y))

# #plot first 3 trees of model
# # xgb.plot.tree(model = cc_xg, trees = 0:2)

# cc_importance_matrix <- xgb.importance(model = cc_xg)
# xgb.plot.importance(cc_importance_matrix, xlab = "Feature Importance")
```

```{r Fit XGBoost Model Infl}

infl_title <- "Naive Infl XGBoost"

infl_xg <-
  xgboost(
    data = econ_xg_train[, c(1:40, 44:49)],
    label = econ_xg_train[, 42],
    nrounds = 1000,
    objective = "reg:squarederror",
    early_stopping_rounds = 6,
    max_depth = 2,
    eta = 0.1,
    nthreads = 4,
  )

infl_pred_xgb <- predict(infl_xg, econ_xg_test[, c(1:40, 44:49)])

infl_yhat <- infl_pred_xgb
infl_y <- econ_xg_test[, 42]
infl_xg_stats <- postResample(infl_yhat, infl_y)
infl_xg_rmse <- infl_xg_stats[[1]]

infl_r <- infl_y - infl_yhat
# plot(infl_r, ylab = "residuals", main = title)

# plot(infl_y,
#      infl_yhat,
#      xlab = "actual",
#      ylab = "predicted",
#      main = title)
# abline(lm(infl_yhat ~ infl_y))

# #plot first 3 trees of model
# # xgb.plot.tree(model = infl_xg, trees = 0:2)

# infl_importance_matrix <- xgb.importance(model = infl_xg)
# xgb.plot.importance(infl_importance_matrix, xlab = "Feature Importance")
```

```{r Fit XGBoost Model Unem}

unem_title <- "Naive Unem XGBoost"

unem_xg <-
  xgboost(
    data = econ_xg_train[, c(1:40, 44:49)],
    label = econ_xg_train[, 43],
    nrounds = 1000,
    objective = "reg:squarederror",
    early_stopping_rounds = 6,
    max_depth = 2,
    eta = 0.1,
    nthreads = 4,
  )

unem_pred_xgb <- predict(unem_xg, econ_xg_test[, c(1:40, 44:49)])

unem_yhat <- unem_pred_xgb
unem_y <- econ_xg_test[, 43]
unem_xg_stats <- postResample(unem_yhat, unem_y)
unem_xg_rmse <- unem_xg_stats[[1]]

unem_r <- unem_y - unem_yhat
# plot(unem_r, ylab = "residuals", main = title)

# plot(unem_y,
#      unem_yhat,
#      xlab = "actual",
#      ylab = "predicted",
#      main = title)
# abline(lm(unem_yhat ~ unem_y))

# #plot first 3 trees of model
# # xgb.plot.tree(model = unem_xg, trees = 0:2)

# unem_importance_matrix <- xgb.importance(model = unem_xg)
# xgb.plot.importance(unem_importance_matrix, xlab = "Feature Importance")
```

```{r Fit XGBoost Model Pubcam}

pubcam_title <- "Naive Pubcam XGBoost"

pubcam_xg <-
  xgboost(
    data = econ_xg_train[, c(1:40, 48:49)],
    label = econ_xg_train[, 44],
    nrounds = 1000,
    objective = "reg:squarederror",
    early_stopping_rounds = 6,
    max_depth = 2,
    eta = 0.36,
    nthreads = 4,
  )

pubcam_pred_xgb <- predict(pubcam_xg, econ_xg_test[, c(1:40, 48:49)])

pubcam_yhat <- pubcam_pred_xgb
pubcam_y <- econ_xg_test[, 44]
pubcam_xg_stats <- postResample(pubcam_yhat, pubcam_y)
pubcam_xg_rmse <- pubcam_xg_stats[[1]]

pubcam_r <- pubcam_y - pubcam_yhat
# plot(pubcam_r, ylab = "residuals", main = title)

# plot(pubcam_y,
#      pubcam_yhat,
#      xlab = "actual",
#      ylab = "predicted",
#      main = title)
# abline(lm(pubcam_yhat ~ pubcam_y))

# #plot first 3 trees of model
# # xgb.plot.tree(model = pubcam_xg, trees = 0:2)

# pubcam_importance_matrix <- xgb.importance(model = pubcam_xg)
# xgb.plot.importance(pubcam_importance_matrix, xlab = "Feature Importance")
```

```{r Fit XGBoost Model SAH}

sah_title <- "Naive SAH XGBoost"

sah_xg <-
  xgboost(
    data = econ_xg_train[, c(1:40, 48:49)],
    label = econ_xg_train[, 45],
    nrounds = 1000,
    objective = "reg:squarederror",
    early_stopping_rounds = 6,
    max_depth = 7,
    eta = 0.18,
    nthreads = 4,
  )

sah_pred_xgb <- predict(sah_xg, econ_xg_test[, c(1:40, 48:49)])

sah_yhat <- sah_pred_xgb
sah_y <- econ_xg_test[, 45]
sah_xg_stats <- postResample(sah_yhat, sah_y)
sah_xg_rmse <- sah_xg_stats[[1]]

sah_r <- sah_y - sah_yhat
# plot(sah_r, ylab = "residuals", main = title)

# plot(sah_y,
#      sah_yhat,
#      xlab = "actual",
#      ylab = "predicted",
#      main = title)
# abline(lm(sah_yhat ~ sah_y))

# #plot first 3 trees of model
# # xgb.plot.tree(model = sah_xg, trees = 0:2)

# sah_importance_matrix <- xgb.importance(model = sah_xg)
# xgb.plot.importance(sah_importance_matrix, xlab = "Feature Importance")
```

```{r Fit XGBoost Model Closure}

closure_title <- "Naive Closure XGBoost"

closure_xg <-
  xgboost(
    data = econ_xg_train[, c(1:40, 48:49)],
    label = econ_xg_train[, 46],
    nrounds = 1000,
    objective = "reg:squarederror",
    early_stopping_rounds = 6,
    max_depth = 7,
    eta = 0.38,
    nthreads = 4,
  )

closure_pred_xgb <- predict(closure_xg, econ_xg_test[, c(1:40, 48:49)])

closure_yhat <- closure_pred_xgb
closure_y <- econ_xg_test[, 46]
closure_xg_stats <- postResample(closure_yhat, closure_y)
closure_xg_rmse <- closure_xg_stats[[1]]

closure_r <- closure_y - closure_yhat
# plot(closure_r, ylab = "residuals", main = title)

# plot(closure_y,
#      closure_yhat,
#      xlab = "actual",
#      ylab = "predicted",
#      main = title)
# abline(lm(closure_yhat ~ closure_y))

# #plot first 3 trees of model
# # xgb.plot.tree(model = closure_xg, trees = 0:2)

# closure_importance_matrix <- xgb.importance(model = closure_xg)
# xgb.plot.importance(closure_importance_matrix, xlab = "Feature Importance")
```

```{r Fit XGBoost Model Policy}

policy_title <- "Naive Policy XGBoost"

policy_xg <-
  xgboost(
    data = econ_xg_train[, c(1:40, 48:49)],
    label = econ_xg_train[, 47],
    nrounds = 1000,
    objective = "reg:squarederror",
    early_stopping_rounds = 6,
    max_depth = 3,
    eta = 0.32,
    nthreads = 4,
  )

policy_pred_xgb <- predict(policy_xg, econ_xg_test[, c(1:40, 48:49)])

policy_yhat <- policy_pred_xgb
policy_y <- econ_xg_test[, 47]
policy_xg_stats <- postResample(policy_yhat, policy_y)
policy_xg_rmse <- policy_xg_stats[[1]]

policy_r <- policy_y - policy_yhat
# plot(policy_r, ylab = "residuals", main = title)

# plot(policy_y,
#      policy_yhat,
#      xlab = "actual",
#      ylab = "predicted",
#      main = title)
# abline(lm(policy_yhat ~ policy_y))

# #plot first 3 trees of model
# # xgb.plot.tree(model = policy_xg, trees = 0:2)

# policy_importance_matrix <- xgb.importance(model = policy_xg)
# xgb.plot.importance(policy_importance_matrix, xlab = "Feature Importance")
```

```{r Predict COVID, CC, Infl, Unem}

end <- econ_traindf %>%
  group_by(country, year) %>%
  filter(year == 2021) %>%
  mutate(month = as.numeric(month)) %>%
  summarize(maxmonth = max(month))

predf <- econ_traindf  %>% filter(F)

for (i in 1:nrow(end)) {
  icountry <- as.character(end$country[i])
  iyear <- as.numeric(end$year[i])
  imonth <- end$maxmonth[1] + 1
  for (j in imonth:12) {
     pred <- cov_test %>% filter(F) %>% mutate(country = factor(country, levels=unique(cov_test$country)))
    pred <- pred %>%
    add_row(country = as.factor(icountry), year = iyear, month = as.factor(j), covid=0)
    pred$covid[1] <- predict(cov_svm_tuned, pred)[1]
    predi <- econ_traindf %>% filter(F) %>% mutate(country = factor(country, levels=unique(cov_test$country)))
    predi <- predi %>%
      right_join(pred, by=c("country", "year", "month", "covid"))
    predi[is.na(predi)] <- 0
    predi$pubcam[1] <- predict(pubcam_svm_tuned, predi)
    predi$sah[1] <- predict(sah_svm_tuned, predi)
    predi$closure[1] <- predict(closure_svm_tuned, predi)
    predi$policy[1] <- predict(policy_svm_tuned, predi)
    
    predf <- predf %>%
    add_row(country=icountry, year=iyear, month=as.factor(j), ccval=predict(cc_svm_tuned, predi)[1], inflval=predict(infl_svm_tuned, predi)[1], unemval=predict(unem_svm_tuned, predi)[1], pubcam=predi$pubcam[1], sah=predi$sah[1], closure=predi$closure[1], policy=predi$policy[1], covid=pred$covid[1])
  }
}

```

```{r}
#plot(mixedcc)
#plot(mixedinfl)
#plot(mixedunem)
```

```{r}
plot(nlincc)
plot(nlininfl)
plot(nlinunem)
```



```{r}


predf %>% ggplot(aes(x=month, y=ccval, group=country, color=country)) + geom_point() + geom_line()+ theme_bw()

groupedcc <- predf %>% 
  group_by(country) %>% 
  summarise(ccval = mean(ccval))

minccval <- predf %>%
  filter(month==7) %>%
  select(country, ccval)

maxccval <- predf %>%
  filter(month==12) %>%
  select(country, ccval)

perc_cc <- maxccval %>%
  mutate(ccval = (maxccval$ccval - minccval$ccval)/minccval$ccval * 100)


predf %>% ggplot(aes(x=month, y=inflval, group=country, color=country)) + geom_point() + geom_line()+ theme_bw()

mininflval <- predf %>%
  filter(month==7) %>%
  select(country, inflval)

maxinflval <- predf %>%
  filter(month==12) %>%
  select(country, inflval)

perc_infl <- maxinflval %>%
  mutate(inflval = (maxinflval$inflval - mininflval$inflval)/mininflval$inflval * 100) %>%
  select(country, inflval)

predf %>% ggplot(aes(x=month, y=unemval, group=country, color=country)) + geom_point() + geom_line()+ theme_bw()


minunemval <- predf %>%
  filter(month==7) %>%
  select(country, unemval)

maxunemval <- predf %>%
  filter(month==12) %>%
  select(country, unemval)

#perc_unem <- maxval %>%
 # mutate(unemval = (maxunemval$unemval - minunemval$unemval)/minunemval$unemval * 100) %>%
 # select(country, inflval)
```

```{r Econ CC SVM Hypergrid}
hyper_grid <- expand.grid(
  cost = 2^seq(-6,5,1),
  gamma= 2^seq(-5,6,1)  
)
e <- NULL

for(j in 1:nrow(hyper_grid)){
  set.seed(123)
  m_svm_untuned <- svm(
    formula = ccval ~ . - inflval - unemval,
    data    = econ_train,
    gamma = hyper_grid$gamma[j],
    cost = hyper_grid$cost[j]
  )  
  
  pred_svm_untuned <-predict(
    m_svm_untuned,
    newdata = econ_test
  )
  
  yhat <- pred_svm_untuned
  y <- econ_test$ccval
  e[j] <- postResample(yhat, y)[1]
}

e[which.min(e)]  #minimum MSE
hyper_grid$gamma[which.min(e)]
hyper_grid$cost[which.min(e)]
```

```{r Econ Infl SVM Hypergrid}
hyper_grid <- expand.grid(
  cost = 2^seq(-6,5,1),
  gamma= 2^seq(-5,5,1)  
)
e <- NULL

for(j in 1:nrow(hyper_grid)){
  set.seed(123)
  m_svm_untuned <- svm(
    formula = inflval ~ . - ccval - unemval,
    data    = econ_train,
    gamma = hyper_grid$gamma[j],
    cost = hyper_grid$cost[j]
  )  
  
  pred_svm_untuned <-predict(
    m_svm_untuned,
    newdata = econ_test
  )
  
  yhat <- pred_svm_untuned
  y <- econ_test$inflval
  e[j] <- postResample(yhat, y)[1]
}

e[which.min(e)]  #minimum MSE
hyper_grid$gamma[which.min(e)]
hyper_grid$cost[which.min(e)]
```


```{r Econ Unem SVM Hypergrid}
hyper_grid <- expand.grid(
  cost = 2^seq(-6,5,1),
  gamma= 2^seq(-5,5,1)  
)
e <- NULL

for(j in 1:nrow(hyper_grid)){
  set.seed(123)
  m_svm_untuned <- svm(
    formula = unemval ~ . - ccval - inflval,
    data    = econ_train,
    gamma = hyper_grid$gamma[j],
    cost = hyper_grid$cost[j]
  )  
  
  pred_svm_untuned <-predict(
    m_svm_untuned,
    newdata = econ_test
  )
  
  yhat <- pred_svm_untuned
  y <- econ_test$unemval
  e[j] <- postResample(yhat, y)[1]
}

e[which.min(e)]  #minimum MSE
hyper_grid$gamma[which.min(e)]
hyper_grid$cost[which.min(e)]
```

```{r Econ Pubcam SVM Hypergrid}
hyper_grid <- expand.grid(
  cost = 2^seq(-6,5,1),
  gamma= 2^seq(-5,6,1)  
)
e <- NULL

for(j in 1:nrow(hyper_grid)){
  set.seed(123)
  m_svm_untuned <- svm(
    formula = pubcam ~ covid + month + year + country,
    data    = econ_train,
    gamma = hyper_grid$gamma[j],
    cost = hyper_grid$cost[j]
  )  
  
  pred_svm_untuned <-predict(
    m_svm_untuned,
    newdata = econ_test
  )
  
  yhat <- pred_svm_untuned
  y <- econ_test$pubcam
  e[j] <- postResample(yhat, y)[1]
}

e[which.min(e)]  #minimum MSE
hyper_grid$gamma[which.min(e)]
hyper_grid$cost[which.min(e)]
```

```{r Econ Sah SVM Hypergrid}
hyper_grid <- expand.grid(
  cost = 2^seq(-6,5,1),
  gamma= 2^seq(-5,5,1)  
)
e <- NULL

for(j in 1:nrow(hyper_grid)){
  set.seed(123)
  m_svm_untuned <- svm(
    formula = sah ~ covid + month + year + country,
    data    = econ_train,
    gamma = hyper_grid$gamma[j],
    cost = hyper_grid$cost[j]
  )  
  
  pred_svm_untuned <-predict(
    m_svm_untuned,
    newdata = econ_test
  )
  
  yhat <- pred_svm_untuned
  y <- econ_test$sah
  e[j] <- postResample(yhat, y)[1]
}

e[which.min(e)]  #minimum MSE
hyper_grid$gamma[which.min(e)]
hyper_grid$cost[which.min(e)]
```

```{r Econ Closure SVM Hypergrid}
hyper_grid <- expand.grid(
  cost = 2^seq(-6,5,1),
  gamma= 2^seq(-5,5,1)  
)
e <- NULL

for(j in 1:nrow(hyper_grid)){
  set.seed(123)
  m_svm_untuned <- svm(
    formula = closure ~ covid + month + year + country,
    data    = econ_train,
    gamma = hyper_grid$gamma[j],
    cost = hyper_grid$cost[j]
  )  
  
  pred_svm_untuned <-predict(
    m_svm_untuned,
    newdata = econ_test
  )
  
  yhat <- pred_svm_untuned
  y <- econ_test$closure
  e[j] <- postResample(yhat, y)[1]
}

e[which.min(e)]  #minimum MSE
hyper_grid$gamma[which.min(e)]
hyper_grid$cost[which.min(e)]
```

```{r Econ Policy SVM Hypergrid}
hyper_grid <- expand.grid(
  cost = 2^seq(-6,5,1),
  gamma= 2^seq(-5,5,1)  
)
e <- NULL

for(j in 1:nrow(hyper_grid)){
  set.seed(123)
  m_svm_untuned <- svm(
    formula = policy ~ covid + month + year + country,
    data    = econ_train,
    gamma = hyper_grid$gamma[j],
    cost = hyper_grid$cost[j]
  )  
  
  pred_svm_untuned <-predict(
    m_svm_untuned,
    newdata = econ_test
  )
  
  yhat <- pred_svm_untuned
  y <- econ_test$policy
  e[j] <- postResample(yhat, y)[1]
}

e[which.min(e)]  #minimum MSE
hyper_grid$gamma[which.min(e)]
hyper_grid$cost[which.min(e)]
```

```{r CC XGBoost Hyperparameters Grid Search}
cc_hyper_grid <- expand.grid(max_depth = seq(1, 7, 1),
                          eta = seq(.1, .4, .02))

cc_xgb_train_rmse <- NULL
cc_xgb_test_rmse <- NULL

for (j in 1:nrow(cc_hyper_grid)) {
  set.seed(123)
  m_xgb_untuned <- xgb.cv(
    data = econ_xg_train[, c(1:40, 44:49)],
    label = econ_xg_train[, 41],
    nrounds = 1000,
    objective = "reg:squarederror",
    early_stopping_rounds = 6,
    nfold = 5,
    max_depth = cc_hyper_grid$max_depth[j],
    eta = cc_hyper_grid$eta[j],
    nthread = 4
  )
  
  cc_xgb_train_rmse[j] <- m_xgb_untuned$evaluation_log$train_rmse_mean[m_xgb_untuned$best_iteration]
  cc_xgb_test_rmse[j] <- m_xgb_untuned$evaluation_log$test_rmse_mean[m_xgb_untuned$best_iteration]
  
  cat(j, "\n")
}
#ideal hyperparamters
cc_hyper_grid[which.min(cc_xgb_test_rmse), ]
```

```{r Infl XGBoost Hyperparameters Grid Search}
infl_hyper_grid <- expand.grid(max_depth = seq(1, 7, 1),
                          eta = seq(.1, .4, .02))

infl_xgb_train_rmse <- NULL
infl_xgb_test_rmse <- NULL

for (j in 1:nrow(infl_hyper_grid)) {
  set.seed(123)
  m_xgb_untuned <- xgb.cv(
    data = econ_xg_train[, c(1:40, 44:49)],
    label = econ_xg_train[, 42],
    nrounds = 1000,
    objective = "reg:squarederror",
    early_stopping_rounds = 6,
    nfold = 5,
    max_depth = infl_hyper_grid$max_depth[j],
    eta = infl_hyper_grid$eta[j],
    nthread = 4
  )
  
  infl_xgb_train_rmse[j] <- m_xgb_untuned$evaluation_log$train_rmse_mean[m_xgb_untuned$best_iteration]
  infl_xgb_test_rmse[j] <- m_xgb_untuned$evaluation_log$test_rmse_mean[m_xgb_untuned$best_iteration]
  
  cat(j, "\n")
}

#ideal hyperparamters
infl_hyper_grid[which.min(infl_xgb_test_rmse), ]
```

```{r Unem XGBoost Hyperparameters Grid Search}
unem_hyper_grid <- expand.grid(max_depth = seq(1, 7, 1),
                          eta = seq(.1, .4, .02))

unem_xgb_train_rmse <- NULL
unem_xgb_test_rmse <- NULL

for (j in 1:nrow(unem_hyper_grid)) {
  set.seed(123)
  m_xgb_untuned <- xgb.cv(
    data = econ_xg_train[, c(1:40, 44:49)],
    label = econ_xg_train[, 43],
    nrounds = 1000,
    objective = "reg:squarederror",
    early_stopping_rounds = 6,
    nfold = 5,
    max_depth = unem_hyper_grid$max_depth[j],
    eta = unem_hyper_grid$eta[j],
    nthread = 4
  )
  
  unem_xgb_train_rmse[j] <- m_xgb_untuned$evaluation_log$train_rmse_mean[m_xgb_untuned$best_iteration]
  unem_xgb_test_rmse[j] <- m_xgb_untuned$evaluation_log$test_rmse_mean[m_xgb_untuned$best_iteration]
  
  cat(j, "\n")
}

#ideal hyperparamters
unem_hyper_grid[which.min(unem_xgb_test_rmse), ]
```

```{r Pubcam XGBoost Hyperparameters Grid Search}
pubcam_hyper_grid <- expand.grid(max_depth = seq(1, 7, 1),
                          eta = seq(.1, .4, .02))

pubcam_xgb_train_rmse <- NULL
pubcam_xgb_test_rmse <- NULL

for (j in 1:nrow(pubcam_hyper_grid)) {
  set.seed(123)
  m_xgb_untuned <- xgb.cv(
    data = econ_xg_train[, c(1:40, 48:49)],
    label = econ_xg_train[, 44],
    nrounds = 1000,
    objective = "reg:squarederror",
    early_stopping_rounds = 6,
    nfold = 5,
    max_depth = pubcam_hyper_grid$max_depth[j],
    eta = pubcam_hyper_grid$eta[j],
    nthread = 4
  )
  
  pubcam_xgb_train_rmse[j] <- m_xgb_untuned$evaluation_log$train_rmse_mean[m_xgb_untuned$best_iteration]
  pubcam_xgb_test_rmse[j] <- m_xgb_untuned$evaluation_log$test_rmse_mean[m_xgb_untuned$best_iteration]
  
  cat(j, "\n")
}

#ideal hyperparamters
pubcam_hyper_grid[which.min(pubcam_xgb_test_rmse), ]
```

```{r Sah XGBoost Hyperparameters Grid Search}
sah_hyper_grid <- expand.grid(max_depth = seq(1, 7, 1),
                          eta = seq(.1, .4, .02))

sah_xgb_train_rmse <- NULL
sah_xgb_test_rmse <- NULL

for (j in 1:nrow(sah_hyper_grid)) {
  set.seed(123)
  m_xgb_untuned <- xgb.cv(
    data = econ_xg_train[, c(1:40, 48:49)],
    label = econ_xg_train[, 45],
    nrounds = 1000,
    objective = "reg:squarederror",
    early_stopping_rounds = 6,
    nfold = 5,
    max_depth = sah_hyper_grid$max_depth[j],
    eta = sah_hyper_grid$eta[j],
    nthread = 4
  )
  
  sah_xgb_train_rmse[j] <- m_xgb_untuned$evaluation_log$train_rmse_mean[m_xgb_untuned$best_iteration]
  sah_xgb_test_rmse[j] <- m_xgb_untuned$evaluation_log$test_rmse_mean[m_xgb_untuned$best_iteration]
  
  cat(j, "\n")
}

#ideal hyperparamters
sah_hyper_grid[which.min(sah_xgb_test_rmse), ]
```

```{r Closure XGBoost Hyperparameters Grid Search}
closure_hyper_grid <- expand.grid(max_depth = seq(1, 7, 1),
                          eta = seq(.1, .4, .02))

closure_xgb_train_rmse <- NULL
closure_xgb_test_rmse <- NULL

for (j in 1:nrow(closure_hyper_grid)) {
  set.seed(123)
  m_xgb_untuned <- xgb.cv(
    data = econ_xg_train[, c(1:40, 48:49)],
    label = econ_xg_train[, 46],
    nrounds = 1000,
    objective = "reg:squarederror",
    early_stopping_rounds = 6,
    nfold = 5,
    max_depth = closure_hyper_grid$max_depth[j],
    eta = closure_hyper_grid$eta[j],
    nthread = 4
  )
  
  closure_xgb_train_rmse[j] <- m_xgb_untuned$evaluation_log$train_rmse_mean[m_xgb_untuned$best_iteration]
  closure_xgb_test_rmse[j] <- m_xgb_untuned$evaluation_log$test_rmse_mean[m_xgb_untuned$best_iteration]
  
  cat(j, "\n")
}

#ideal hyperparamters
closure_hyper_grid[which.min(closure_xgb_test_rmse), ]
```

```{r Policy XGBoost Hyperparameters Grid Search}
policy_hyper_grid <- expand.grid(max_depth = seq(1, 7, 1),
                          eta = seq(.1, .4, .02))

policy_xgb_train_rmse <- NULL
policy_xgb_test_rmse <- NULL

for (j in 1:nrow(policy_hyper_grid)) {
  set.seed(123)
  m_xgb_untuned <- xgb.cv(
    data = econ_xg_train[, c(1:40, 48:49)],
    label = econ_xg_train[, 47],
    nrounds = 1000,
    objective = "reg:squarederror",
    early_stopping_rounds = 6,
    nfold = 5,
    max_depth = policy_hyper_grid$max_depth[j],
    eta = policy_hyper_grid$eta[j],
    nthread = 4
  )
  
  policy_xgb_train_rmse[j] <- m_xgb_untuned$evaluation_log$train_rmse_mean[m_xgb_untuned$best_iteration]
  policy_xgb_test_rmse[j] <- m_xgb_untuned$evaluation_log$test_rmse_mean[m_xgb_untuned$best_iteration]
  
  cat(j, "\n")
}

#ideal hyperparamters
policy_hyper_grid[which.min(policy_xgb_test_rmse), ]
```

```{r COVID SVM Hypergrid}
hyper_grid <- expand.grid(
  cost = 2^seq(-5,5,1),
  gamma= 2^seq(-5,5,1)  
)
e <- NULL

for(j in 1:nrow(hyper_grid)){
  set.seed(123)
  m_svm_untuned <- svm(
    formula = covid ~ .,
    data    = cov_train,
    gamma = hyper_grid$gamma[j],
    cost = hyper_grid$cost[j]
  )  
  
  pred_svm_untuned <-predict(
    m_svm_untuned,
    newdata = cov_test
  )
  
  yhat <- pred_svm_untuned
  y <- cov_test$covid
  e[j] <- postResample(yhat, y)[1]
}

e[which.min(e)]  #minimum MSE
hyper_grid$gamma[which.min(e)]
hyper_grid$cost[which.min(e)]
```

```{r XGBoost COVID Hyperparameters Grid Search}
cov_hyper_grid <- expand.grid(max_depth = seq(1, 7, 1),
                          eta = seq(.1, .4, .02))

cov_xgb_train_rmse <- NULL
cov_xgb_test_rmse <- NULL

for (j in 1:nrow(cov_hyper_grid)) {
  set.seed(123)
  m_xgb_untuned <- xgb.cv(
    data = cov_xg_train[, 1:41],
    label = cov_xg_train[, 42],
    nrounds = 1000,
    objective = "reg:squarederror",
    early_stopping_rounds = 6,
    nfold = 5,
    max_depth = cov_hyper_grid$max_depth[j],
    eta = cov_hyper_grid$eta[j],
    nthread = 4
  )
  
  cov_xgb_train_rmse[j] <- m_xgb_untuned$evaluation_log$train_rmse_mean[m_xgb_untuned$best_iteration]
  cov_xgb_test_rmse[j] <- m_xgb_untuned$evaluation_log$test_rmse_mean[m_xgb_untuned$best_iteration]
  
  cat(j, "\n")
}

#ideal hyperparamters
cov_hyper_grid[which.min(cov_xgb_test_rmse), ]
```